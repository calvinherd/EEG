# -*- coding: utf-8 -*-
"""EEG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RA3J2hmKrbdojZ7vph00OfKYHGpH7kD9
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import os
from tensorflow.keras.layers import Dense, Flatten, LSTM, Dropout, Embedding, SimpleRNN, Conv2D, Conv1D, MaxPooling1D, GRU, SimpleRNN 
from tensorflow.keras.utils import to_categorical
import random
from tensorflow import convert_to_tensor
from collections import Counter
from keras.models import Sequential

import mne
sample_data_folder = mne.datasets.sample.data_path()
sample_data_raw_file = os.path.join(sample_data_folder, 'MEG', 'sample','sample_audvis_filt-0-40_raw.fif')
raw = mne.io.read_raw_fif(sample_data_raw_file)

#raw = raw.pick(picks=["eeg","eog"])

# set up and fit the ICA
ica = mne.preprocessing.ICA(n_components=20, random_state=97, max_iter=800)
ica.fit(raw)
ica.exclude = [1, 2]  # details on how we picked these are omitted here
ica.plot_properties(raw, picks=ica.exclude)
orig_raw = raw.copy()
raw.load_data()
ica.apply(raw)

chs = ['EEG 001', 'EEG 002', 'EEG 003', 'EEG 004', 'EEG 005', 'EEG 006', 'EEG 007', 'EEG 008', 'EEG 009', 'EEG 010', 'EEG 011', 'EEG 012', 'EEG 013', 'EEG 014', 'EEG 015', 'EEG 016', 'EEG 017', 'EEG 018', 'EEG 019', 'EEG 020', 'EEG 021', 'EEG 022', 'EEG 023', 'EEG 024', 'EEG 025', 'EEG 026', 'EEG 027', 'EEG 028', 'EEG 029', 'EEG 030', 'EEG 031', 'EEG 032', 'EEG 033', 'EEG 034', 'EEG 035', 'EEG 036', 'EEG 037', 'EEG 038', 'EEG 039', 'EEG 040', 'EEG 041', 'EEG 042', 'EEG 043', 'EEG 044', 'EEG 045', 'EEG 046', 'EEG 047', 'EEG 048', 'EEG 049', 'EEG 050', 'EEG 051', 'EEG 052', 'EEG 053', 'EEG 054', 'EEG 055', 'EEG 056', 'EEG 057', 'EEG 058', 'EEG 059', 'EEG 060', 'EOG 061']

chan_idxs = [raw.ch_names.index(ch) for ch in chs]
orig_raw.plot(order=chan_idxs, start=12, duration=4)
raw.plot(order=chan_idxs, start=12, duration=4)
events = mne.find_events(raw, stim_channel='STI 014')
event_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,
              'visual/right': 4, 'smiley': 5, 'buttonpress': 32}
fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=raw.info['sfreq'],
                          first_samp=raw.first_samp)
reject_criteria = dict(mag=4000e-15,     # 4000 fT
                       grad=4000e-13,    # 4000 fT/cm
                       eeg=150e-6,       # 150 ÂµV
                       eog=250e-6)
epochs = mne.Epochs(raw, events, event_id=event_dict, tmin=-0.2, tmax=0.5,
                    reject=reject_criteria, preload=True)

event_dict = {'auditory/left': 1, 'auditory/right': 2, 'visual/left': 3,
              'visual/right': 4, 'smiley': 5, 'buttonpress': 32}
types = []
data=[]
labels=[]
types.append(epochs['auditory/left'].get_data())
print(len(types[-1]))
types.append(epochs['auditory/right'].get_data())
print(len(types[-1]))
types.append(epochs['smiley'].get_data())
print(len(types[-1]))
types.append(epochs['buttonpress'].get_data())
print(len(types[-1]))
types.append(epochs['visual/right'].get_data())
print(len(types[-1]))
types.append(epochs['visual/left'].get_data())
print(len(types[-1]))
for val in range(6):
  t=types[val]
  labels+=[val for i in range(len(t))]
  for wave in t:
    data.append(wave)
mapIndexPosition = list(zip(data, labels))
random.shuffle(mapIndexPosition)
data, labels = zip(*mapIndexPosition)
data = convert_to_tensor(np.array(data)*1e12)
labels = convert_to_tensor(to_categorical(labels))

def NN():
  model = Sequential([
    Flatten(input_shape=(376, 106)),
    Dense(128, activation='relu'),
    Dense(6, activation='softmax')
  ])
  model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])
  return model

def CNN():
  model = Sequential()
  model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(376, 106)))
  model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))
  model.add(Dropout(0.5))
  model.add(MaxPooling1D(pool_size=2))
  model.add(Flatten())
  model.add(Dense(100, activation='relu'))
  model.add(Dense(6, activation='softmax'))
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model
def RNN():
  model = Sequential()
  model.add(SimpleRNN(50))

  model.add(Dense(100, activation='relu'))
  model.add(Dense(6, activation='softmax'))
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
  return model

nn=NN()
nn.fit(x=data, y= labels, validation_split=.2,shuffle=True, verbose = 2, epochs = 4, batch_size=32)

cnn=CNN()
cnn.fit(x=data, y= labels, validation_split=.2, shuffle = True, verbose = 2, epochs = 4, batch_size=32)

rnn=RNN()
rnn.fit(x=data, y= labels, validation_split=.2, shuffle = True, verbose = 2, epochs = 75, batch_size=32)



